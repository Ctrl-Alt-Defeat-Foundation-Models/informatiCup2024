## Fool AI Detectors
### Foundation Models

Team members: Levi Otterbach, Lukas Müller, Max Buchholz, Raphael Weber

## Context
This project proposal is based on the task description of the competition informatiCup by the Gesellschaft für Informatik, as we plan to also submit the project at the competetion.

### Problem
Images generated with text-to-image generators look more and more realistic. Large language models write increasingly complex texts and answer questions, so that they can hardly be distinguished from a human being. This not only creates tremendous potential to produce creative content and automating workflows, but also the danger of fake news, which can be generated with minimal effort. In order to counter this danger, it is necessary to develop new models that can that reliably and securely detects AI-generated content and thus prevent fake news created by generative models.

The approach the issue, we first conduct a technical market analysis. We examine existing AI models on the market that can be used for text and image generation. In addition, we are to evaluate which models can be used for the detection of AI-generated content and assess their performance. In the second step, we develope completely new tool for AI content. The idea is to develop a program that reliably tricks existing AI detectors with little effort by making minimal changes to AI-generated text or images. This can then be used during training of a new model for augmenting data to robustly train a new model against such modifications. For this reason, the software we develop shall be fast and reliable on images of arbitrary size and text of arbitrary length.

### Tasks:

